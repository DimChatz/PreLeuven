{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e94aa0dd",
   "metadata": {},
   "source": [
    "# Thesis Mammo Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98dd7e1c",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "862f4cc2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13404/2554227928.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks\timport ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras import Model\n",
    "import keras.backend as K\n",
    "from keras.models import load_model\n",
    "from skimage.draw import disk\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3891ed0c",
   "metadata": {},
   "source": [
    "### Load data from CBIS-DDSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d59576f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader_ddsm(filepath,size):\n",
    "    count = 0\n",
    "    #array for reading into\n",
    "    input_data=np.zeros((size,512,512,1),dtype=np.uint8)\n",
    "    # Read\n",
    "    for file in os.listdir(filepath):\n",
    "        # Find paths\n",
    "        if (count>5):\n",
    "            test_path = os.path.join(filepath, file)\n",
    "            data=cv2.imread(test_path,0)\n",
    "            input_data[count,:,:,0] = data\n",
    "        count = count + 1\n",
    "        if (count>=11):\n",
    "            break;\n",
    "    return input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec13716",
   "metadata": {},
   "source": [
    "### Load data from MIAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2b1d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader_mias(filepath, subset):\n",
    "    # Initiliaze return arrays\n",
    "    global size\n",
    "    if subset==\"train\":\n",
    "        size = 312\n",
    "    elif subset==\"val\":\n",
    "        size = 18\n",
    "    elif subset==\"test\":\n",
    "        size = 18\n",
    "    input_data=np.zeros((size*4,128,128,1),dtype=np.uint8)\n",
    "    output_data=np.zeros((size*4,128,128,1),dtype=np.uint8)\n",
    "    # Open file to read and create loop\n",
    "    with open(str(filepath)+str(subset)+\".txt\", \"r\") as input_file:\n",
    "        # Count to pass through the file\n",
    "        count=0\n",
    "        for line in input_file:\n",
    "            line=line.split(\" \")\n",
    "            data=cv2.imread(filepath+str(line[0])+\".pgm\",0)\n",
    "            data=cv2.resize(data, (128,128), interpolation=cv2.INTER_CUBIC)\n",
    "            input_data[count,:,:,0]=data\n",
    "            # Flipped\n",
    "            input_data[size+count,:,:,0] = np.flip(input_data[count,:,:,0], 1)\n",
    "            # Zoom\n",
    "            cropped_in_img = input_data[count,14:113,14:113,0]\n",
    "            input_data[size*2+count,:,:,0]  = cv2.resize(cropped_in_img, (128, 128), interpolation=cv2.INTER_CUBIC)\n",
    "            # Zoom - flip\n",
    "            input_data[size*3+count,:,:,0]=np.flip(input_data[size*2+count,:,:,0], 1)\n",
    "            # Case of benevolent\n",
    "            if line[3]==\"B\":\n",
    "                # BE VERY CAREFUL WITH THIS DISK FUNCTION --- IT TAKES IN THE FORMAT (Y,X) NOT (X,Y)\n",
    "                rr, cc = disk(((1024-(int(line[5])))/8, (int(line[4]))/8), int(line[6])/8, shape=(128,128))\n",
    "                output_data[count,rr,cc,0]=1\n",
    "                # Flipped\n",
    "                output_data[size+count,:,:,0]=np.flip(output_data[count,:,:,0], 1)\n",
    "                # Zoom\n",
    "                cropped_img = output_data[count,14:113,14:113,0]\n",
    "                output_data[size*2+count,:,:,0]  = cv2.resize(cropped_img, (128, 128), interpolation=cv2.INTER_CUBIC)\n",
    "                # Zoom - flip\n",
    "                output_data[size*3+count,:,:,0]=np.flip(output_data[size*2+count,:,:,0], 1)\n",
    "            # Case of malevolent\n",
    "            elif line[3]==\"M\":\n",
    "                rr, cc = disk(((1024-(int(line[5])))/8, (int(line[4]))/8), int(line[6])/8, shape=(128,128))\n",
    "                output_data[count,rr,cc,0]=1\n",
    "                # Flipped\n",
    "                output_data[size+count,:,:,0]=np.flip(output_data[count,:,:,0], 1)\n",
    "                # Zoom\n",
    "                cropped_img = output_data[count,14:113,14:113,0]\n",
    "                output_data[size*2+count,:,:,0]  = cv2.resize(cropped_img, (128, 128), interpolation=cv2.INTER_CUBIC)\n",
    "                # Zoom - flip\n",
    "                output_data[size*3+count,:,:,0]=np.flip(output_data[size*2+count,:,:,0], 1)\n",
    "            count=count+1\n",
    "    input_data=input_data.astype(np.float32)\n",
    "    input_data = np.asarray(input_data)\n",
    "    # Reshape output_data in order to be used in the weights function\n",
    "    output_data[output_data>1] = 1\n",
    "    output_data=output_data.astype(np.float32)\n",
    "    output_data = np.asarray(output_data)\n",
    "    return input_data, output_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52193480",
   "metadata": {},
   "source": [
    "## Functions for Neural model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0596049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of block functions\n",
    "def encoder_block(inputs,filter_size, kernel_size):\n",
    "    conv = Conv2D(filter_size, (1,kernel_size), activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\n",
    "    conv = Conv2D(filter_size, (kernel_size,1), activation='relu', padding='same', kernel_initializer='he_normal')(conv)\n",
    "    conv = BatchNormalization(axis=-1)(conv)\n",
    "    conv = Conv2D(filter_size, (1,kernel_size), activation='relu', padding='same', kernel_initializer='he_normal')(conv)\n",
    "    conv = Conv2D(filter_size, (kernel_size,1), activation='relu', padding='same', kernel_initializer='he_normal')(conv)\n",
    "    conv = BatchNormalization(axis=-1)(conv)\n",
    "    pool = MaxPooling2D(pool_size=(2, 2))(conv)\n",
    "    drop = Dropout(0.3)(pool)\n",
    "    return conv,drop\n",
    "\n",
    "def bottleneck(inputs,filter_size, kernel_size):\n",
    "    conv = Conv2D(filter_size, (1,kernel_size), activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\n",
    "    conv = Conv2D(filter_size, (kernel_size,1), activation='relu', padding='same', kernel_initializer='he_normal')(conv)\n",
    "    conv = BatchNormalization(axis=-1)(conv)\n",
    "    conv = Conv2D(filter_size, (1,kernel_size), activation='relu', padding='same', kernel_initializer='he_normal')(conv)\n",
    "    conv = Conv2D(filter_size, (kernel_size,1), activation='relu', padding='same', kernel_initializer='he_normal')(conv)\n",
    "    conv = BatchNormalization(axis=-1)(conv)\n",
    "    return conv\n",
    "\n",
    "def decoder_block(input1, input2,filter_size, kernel_size):\n",
    "    up = concatenate([Conv2DTranspose(filter_size, (kernel_size,kernel_size), strides=(2, 2), padding='same')(input1), input2], axis=3)\n",
    "    conv = Conv2D(filter_size, (1,kernel_size), activation='relu', padding='same', kernel_initializer='he_normal')(up)\n",
    "    conv = Conv2D(filter_size, (kernel_size,1), activation='relu', padding='same', kernel_initializer='he_normal')(conv)\n",
    "    conv = BatchNormalization(axis=-1)(conv)\n",
    "    conv = Conv2D(filter_size, (1,kernel_size), activation='relu', padding='same', kernel_initializer='he_normal')(conv)\n",
    "    conv = Conv2D(filter_size, (kernel_size,1), activation='relu', padding='same', kernel_initializer='he_normal')(conv)\n",
    "    conv = BatchNormalization(axis=-1)(conv)\n",
    "    return conv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f065d2",
   "metadata": {},
   "source": [
    "# Main Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f680e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main model\n",
    "def unet_model(num_classes, optimizer, loss_metric, metrics, sample_width, sample_height, lr=1e-5):\n",
    "    inputs = Input((sample_width, sample_height, 1))\n",
    "    \n",
    "    # Downsampling\n",
    "    conv1, drop1 = encoder_block(inputs,64,3)\n",
    "    conv2, drop2 = encoder_block(drop1,128,3)\n",
    "    conv3, drop3 = encoder_block(drop2,256,3)\n",
    "    conv4, drop4 = encoder_block(drop3,512,3)\n",
    "    \n",
    "    # Bottleneck\n",
    "    conv5 = bottleneck(drop4,1024,3)\n",
    "\n",
    "    # Upsampling\n",
    "    conv6 = decoder_block(conv5,conv4,512,2)\n",
    "    conv7 = decoder_block(conv6,conv3,256,2)\n",
    "    conv8 = decoder_block(conv7,conv2,128,2)\n",
    "    conv9 = decoder_block(conv8,conv1,64,2)\n",
    "\n",
    "    # Output\n",
    "    conv10 = Conv2D(num_classes, 1, padding='same', activation='softmax')(conv9)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[conv10])\n",
    "\n",
    "    model.compile(optimizer=optimizer(lr=lr), loss=loss_metric, metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300fdfba",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac6ae00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize images\n",
    "def normalize(image):\n",
    "    arr = image/255\n",
    "    return arr\n",
    "\n",
    "# Dice Coefficient to work with Tensorflow\n",
    "def dice_coef(y_true, y_pred, smooth=0.001):\n",
    "    intersection = K.sum(y_true * y_pred)\n",
    "    union = K.sum(y_true) + K.sum(y_pred)\n",
    "    dice = (2. * intersection + smooth)/(union + smooth)\n",
    "    return dice\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred,smooth=0.001):\n",
    "    return -dice_coef(y_true, y_pred, smooth)\n",
    "\n",
    "# Function to display images\n",
    "def display(display_list):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Predictions of images\n",
    "def show_predictions(tensor_in,tensor_out, num=1):\n",
    "    for i in range(num):\n",
    "        print(\"The input tensor has shape \", tensor_in[:,:,:,:].shape)\n",
    "        pred_mask = unet.predict(tensor_in[:,:,:,:])\n",
    "        pred_mask_test = create_mask(pred_mask)\n",
    "        print(\"The mask initially has shape\", pred_mask_test.shape)\n",
    "        pred_mask_test = pred_mask_test[i,:,]\n",
    "        print(\"The mask keeping a slice has shape\", pred_mask_test.shape)\n",
    "        print(np.sqrt(pred_mask_test.shape[0]))\n",
    "        pred_mask_test = np.reshape(pred_mask_test, (int(np.sqrt(pred_mask_test.shape[0])),int(np.sqrt(pred_mask_test.shape[0])),1))\n",
    "        print( \"The reformed mask has shape \",pred_mask_test.shape)\n",
    "        pred_mask_test = np.max(pred_mask_test) - pred_mask_test\n",
    "        #pred_mask_test = pred_mask_test.reshape((pred_mask_test.shape[1],pred_mask_test.shape[2],1))\n",
    "        display([tensor_in[i,:,:,:], tensor_out[i,:,:,:], pred_mask_test[:,:,:]])\n",
    "\n",
    "# Callback to display masks as model trains at epoch end\n",
    "class DisplayCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        clear_output(wait=True)\n",
    "        show_predictions(test_input,test_masks)\n",
    "\n",
    "def create_mask(pred_mask):\n",
    "    pred_mask = np.argmax(pred_mask, axis = -1)\n",
    "    return pred_mask\n",
    "\n",
    "def iou(y_true, y_pred):\n",
    "    intersection = K.sum(y_true * y_pred)\n",
    "    union =  K.sum(y_true) +  K.sum(y_pred) - intersection\n",
    "    x = (intersection + 1e-15) / (union + 1e-15)\n",
    "    return x\n",
    "\n",
    "def iou_loss(y_true, y_pred):\n",
    "    return -iou(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c8a49b",
   "metadata": {},
   "source": [
    "# Main programm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ad53f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPERPARAMETERS\n",
    "\n",
    "#Filepath of datasets DDSM\n",
    "filepath_train_img = \"D:/Windows/torrents/manifest-ZkhPvrLo5216730872708713142/Processed/train/images/\"\n",
    "filepath_train_mask = \"D:/Windows/torrents/manifest-ZkhPvrLo5216730872708713142/Processed/train/masks/\"\n",
    "filepath_test_img = \"D:/Windows/torrents/manifest-ZkhPvrLo5216730872708713142/Processed/test/images/\"\n",
    "filepath_test_mask = \"D:/Windows/torrents/manifest-ZkhPvrLo5216730872708713142/Processed/test/masks/\"\n",
    "\n",
    "train_mode = False\n",
    "\n",
    "# Get data DDSM\n",
    "train_input = dataloader_ddsm(filepath_train_img,83)\n",
    "train_masks = dataloader_ddsm(filepath_train_mask,83)\n",
    "test_input = dataloader_ddsm(filepath_test_img,93)\n",
    "test_masks = dataloader_ddsm(filepath_test_mask,93)\n",
    "\n",
    "# Normalize images\n",
    "train_input = normalize(train_input)\n",
    "test_input = normalize(test_input)\n",
    "test_masks = normalize(test_masks)\n",
    "train_masks = normalize(train_masks)\n",
    "\n",
    "print(\"The train input has dimensions \",train_input.shape)\n",
    "\n",
    "if train_mode == True:\n",
    "    # Load model\n",
    "    unet = unet_model(num_classes = 2, optimizer = Adam, loss_metric = iou_loss, metrics = dice_coef, sample_width = test_input.shape[1], sample_height = test_input.shape[2], lr=1e-3)\n",
    "    unet.compile(optimizer=Adam(lr=1e-3), loss = iou_loss,  metrics=[dice_coef])\n",
    "    unet.summary()\n",
    "\n",
    "    # Define callbacks\n",
    "    callbacks = [\n",
    "    ModelCheckpoint(filepath=\"C:/Users/xatzo/Downloads/unet_new.h5\", monitor='val_loss', verbose=1, save_best_only=True, mode='min'),\n",
    "    ReduceLROnPlateau(monitor=\"val_loss\", patience=2, factor=0.1, verbose=1, mode='min', min_lr=1e-8),\n",
    "    EarlyStopping(monitor=\"val_loss\", patience=5, verbose=1),\n",
    "    DisplayCallback()\n",
    "    ]\n",
    "\n",
    "    show_predictions(test_input,test_masks)\n",
    "    history = unet.fit(x=test_input, y=test_masks, \n",
    "        validation_data=(test_input,test_masks), \n",
    "    batch_size=1, epochs=50, callbacks=callbacks)\n",
    "\n",
    "    # Test model\n",
    "    show_predictions(test_input, test_masks, num=test_input.shape[0])\n",
    "\n",
    "else:\n",
    "    # Initialize model from weights\n",
    "    unet = unet_model(num_classes=2, optimizer=Adam, loss_metric=iou_loss,\n",
    "                       metrics=[dice_coef], sample_width=train_input.shape[1], sample_height=train_input.shape[2],lr=1e-3)\n",
    "    unet = load_model('C:/Users/xatzo/Downloads/unet64_iou4_drop3.h5', custom_objects={\"dice_coef\": dice_coef, \"dice_coef_loss\": dice_coef_loss, \"iou\": iou, \"iou_loss\": iou_loss})\n",
    "    unet.summary()\n",
    "    \n",
    "    # Test model\n",
    "    show_predictions(train_input, train_masks, num=5)\n",
    "    show_predictions(test_input, test_masks, num=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d07990",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
